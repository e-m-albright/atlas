# Deep Learning

### **Deep Learning**

#### **Graphical Models**

**Bayes Nets**

**Boltzmann Machines**  


#### **Neural Networks**

**Rectified Linear Units \(ReLU's\)**

**Convolutional**

**Recurrent**

#### **Formal Logic**

**\(AI survey course\)**

**First Order Logic**

**demorgan's law**

**\(PQ\)PQ**

**\(PQ\)PQ**  


**Conjunctive normal form**

**ABCD**  


**This shit**

**A\(BC\)**

**\(ABC\)\(\(BC\)A\)**

**\(ABC\) \(\(BC\)A\)**  


**STRIPS / PDDL**

**intial state**

**actions**

**goal**

**predicates**

**objects**  
  


#### **Search**

**Heuristics:**

**consistent : triangle inequality. state to goal is less than or equal to state to intermediary state to goal**

**admissible: never overestimates distance**  


**Alpha-beta-pruning**

**Expectation minimization \(wasn't it?\)**  
  


**Simulated Annealing**

**allows bad moves with probability e^deltaE/T, proportional to "energy" difference of move modulated by temperature - basically more scattered/jumping until the search "cools off".**

**not frequently used nowadays**  


**parametric optimization**

**combinatorial optimization problem - state space is finite**

**parametric - state space is real valued**  


#### **Reinforcement Learning**

**U\(s\)=R\(s,a\)+s'P\(s'\|s,a\)U\(s'\)**

**Utility of a state is equal to the reward of the state plus the action, plus the sum of the future states times their probability of transition there from an action discounted for being in the future**

