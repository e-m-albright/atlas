# Regression

linear regression

### Correlation does not imply Causation

A correlation between x and y means there is a linear trend that exists between the two variables  


### Simpson's Paradox

The direction of an association between two variables can change after we include a third variable and analyze the data at separate levels of that variable

Example: school admissions, male vs female applications, a lower proportion of women are admitted. If you look at each department each shows a higher level of female admittance, but due to women applying more to more selective departments \(history\) vs STEM, they overall have lower admittance.

1. Scatterplot
2. Normal distribution for residuals
3. Expected \(Average value\) of residuals = 0
4. Residuals are independent
5. Equal variance for residuals

R^2  
need to review this...  
R-sq=R^2  
the proportion of variation in y explained by the model  
SStotal  
want to be close to 1, its between 0-1, SSE, total variabilty  
linear model with one S, r^2 is literally r^2



Residual Standard Error

Take the average of the y, the error is real y against the average, and is called "the variation". Introducing a linear model \(sloped line\) you should see improvement, and the error should shrink. The degree of reduction is the "explained" variation. The SSR is the variation in y reduced by the model.

### Assumptions

r = sqrt\(R^2\)

assumptions for linear regression - your residuals \(y-y\_mean\)-&gt;residual, should be a normal distribution on the residuals,

#### Independence

Do you see any clear pattern in the residuals? \(x axis fitted, y axis residuals??\)







